package com.kafka.consumer.group.producer;

import com.kafka.consumer.group.model.Order;
import com.kafka.consumer.group.partition.CustomPartition;
import com.kafka.consumer.group.serializers.CustomSerializer;
import org.apache.kafka.clients.consumer.ConsumerConfig;
import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.ProducerConfig;
import org.apache.kafka.clients.producer.ProducerRecord;
import org.apache.kafka.common.serialization.StringSerializer;

import java.util.Properties;
import java.util.UUID;
import java.util.concurrent.ExecutionException;

public class OrderProducer {

    public static void publishMessage() throws ExecutionException, InterruptedException {

        Properties props = new Properties();
        props.setProperty(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "127.0.0.1:9092");
        props.setProperty(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
        props.setProperty(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, CustomSerializer.class.getName());
        props.setProperty(ProducerConfig.PARTITIONER_CLASS_CONFIG, CustomPartition.class.getName());
        props.setProperty(ProducerConfig.TRANSACTIONAL_ID_CONFIG, "order-consumer-group-" + UUID.randomUUID());
        props.setProperty(ConsumerConfig.CLIENT_ID_CONFIG, "order-producer-client ");

        // how many partitions should receive the message before broker successfully acknowledge.
        // 0 -> producer send the message and wait the response from the broker
        // 1 -> produce received acknowledgement from the broker only if the leader replica successfully receive the message.
        // all -> if all replica receive the message. more latency(wait time for producers)
        props.setProperty(ProducerConfig.ACKS_CONFIG, "all");
        // if application is too fast and producer has to handle the request it reserves some memory(default 256 byte) to send the message.
        props.setProperty(ProducerConfig.BUFFER_MEMORY_CONFIG, "3647");
        // send message in compressed format ex. snappy(less cpu used) google provided.
        // gzip (best use, network bandwidth uses)
        props.setProperty(ProducerConfig.COMPRESSION_TYPE_CONFIG, "snappy");
        props.setProperty(ProducerConfig.RETRIES_CONFIG, "2"); // default 100ms
        props.setProperty(ProducerConfig.RETRY_BACKOFF_MS_CONFIG, "400");
        // memory allocation to the batch size
        props.setProperty(ProducerConfig.BATCH_SIZE_CONFIG, "76850900");
        // complements to the batch size
        props.setProperty(ProducerConfig.LINGER_MS_CONFIG, "200");
        props.setProperty(ProducerConfig.REQUEST_TIMEOUT_MS_CONFIG, "200");
        // to remove duplicate messages each message bind with unique serial-number(generated by producer) and producerId(generated by kafka broker)
        props.setProperty(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG, "true");

        Order order1 = new Order(UUID.randomUUID().toString(), "Nokia ChromeBook", 100, "Nokia Store");
        Order order2 = new Order(UUID.randomUUID().toString(), "RealMe Pro", 200, "RealMe Store");

        KafkaProducer<String, Order> producer = new KafkaProducer<>(props);
        producer.initTransactions();
        ProducerRecord<String, Order> record1 = new ProducerRecord<>("order-consumer-group-topic", order1.getOwnerName(), order1);
        ProducerRecord<String, Order> record2 = new ProducerRecord<>("order-consumer-group-topic", order2.getOwnerName(), order2);

        try {
            producer.beginTransaction();
            producer.send(record1);
            producer.send(record2);
            producer.commitTransaction();
        } catch (Exception e) {
            producer.abortTransaction();
            e.printStackTrace();
        } finally {
            producer.close();
        }

    }
}
